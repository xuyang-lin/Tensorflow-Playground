{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "# import cufflinks as cf\n",
    "\n",
    "pd.set_option(\"display.max_columns\",1000)\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queue & Coordinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 12.06169987  28.70277214 -10.63586807  -4.9760704 ] 1\n",
      "1 [ -3.46140981   3.51335835   0.22240219  18.45738029] 0\n",
      "2 [-12.2756319    6.17782688   3.51156044  -2.59906912] 1\n",
      "3 [ 10.12537003   7.38464594  19.89593697  -1.42829859] 1\n",
      "4 [ -8.45846558 -10.87396812   6.12136126  -1.9430933 ] 1\n",
      "5 [  9.43890858  22.02574348   5.98641253  14.76107407] 0\n",
      "6 [  4.83206797  -7.18120527  11.14713287  -9.94617176] 1\n",
      "7 [ 10.79069138 -19.49463463   4.67529821  12.83173561] 1\n",
      "8 [-10.77382183   1.86574149  -8.7260437   10.24249554] 1\n",
      "9 [ 7.15000868  6.95936489 -3.12906528  8.24206448] 1\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 1000\n",
    "NUM_THREADS = 4\n",
    "# Generating some simple data\n",
    "# create 1000 random samples, each is a 1D array from the normal distribution N(1, 100)\n",
    "data = 10 * np.random.randn(N_SAMPLES,4) + 1\n",
    "# create 1000 random labels of 0 and 1\n",
    "label = np.random.randint(0,2,size=N_SAMPLES)\n",
    "\n",
    "queue = tf.FIFOQueue(capacity=50,dtypes=[tf.float32,tf.int32],shapes=[[4],[]])\n",
    "\n",
    "enqueue_op = queue.enqueue_many([data,label])\n",
    "dequeue_op = queue.dequeue()\n",
    "\n",
    "# create NUM_THREADS to do enqueue\n",
    "qr = tf.train.QueueRunner(queue,enqueue_ops=[enqueue_op] * NUM_THREADS)\n",
    "with tf.Session() as sess:\n",
    "    # Create a coordinator, launch the queue runner threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = qr.create_threads(sess,coord=coord,start=True)\n",
    "    try:\n",
    "        for step in range(10):\n",
    "            if coord.should_stop():\n",
    "                break\n",
    "            data_batch,label_batch = sess.run(dequeue_op)\n",
    "            print(step,data_batch,label_batch)\n",
    "    except Exception as e:\n",
    "        coord.request_stop(e)\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(enqueue_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reader - CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_FEATURES = 9\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "############# Read CSV Files ################\n",
    "\n",
    "# Create a queue that hould the names of all files\n",
    "filename_queue = tf.train.string_input_producer([\"/home/ec2-user/data/tf_playground/heart.csv\"])\n",
    "reader = tf.TextLineReader(skip_header_lines=1) # TF does not care about header\n",
    "\n",
    "# Read one line from the file in queue\n",
    "key,value = reader.read(filename_queue)\n",
    "\n",
    "############# Decoding ################\n",
    "\n",
    "# Decoding with data type\n",
    "record_defaults = [[np.float32(1.0)] for _ in range(N_FEATURES)]\n",
    "record_defaults[4]=[\" \"]\n",
    "record_defaults.append([1])\n",
    "content = tf.decode_csv(value,record_defaults=record_defaults)\n",
    "\n",
    "############# Preprocessing ################\n",
    "\n",
    "# Convert the 5th column (present/absent) to the binary value 0 and 1\n",
    "condition = tf.equal(content[4],tf.constant('Present'))\n",
    "content[4] = tf.where(condition,tf.constant(1.0),tf.constant(0.0))\n",
    "\n",
    "# Pack all 9 features into a tensor\n",
    "features = tf.stack(content[:N_FEATURES])\n",
    "# Assign the last column to label\n",
    "label = content[-1]\n",
    "\n",
    "############# Build Shuffle Batch ################\n",
    "\n",
    "# minimum number elements in the queue after a dequeue, used to ensure\n",
    "# that the samples are sufficiently mixed\n",
    "# I think 10 times the BATCH_SIZE is sufficient\n",
    "min_after_dequeue = 10 * BATCH_SIZE\n",
    "\n",
    "# the maximum number of elements in the queue\n",
    "capacity = 20 * BATCH_SIZE\n",
    "\n",
    "# shuffle the data to generate BATCH_SIZE sample pairs\n",
    "feature_batch,label_batch = tf.train.shuffle_batch([features,label],batch_size=BATCH_SIZE,\n",
    "                                                  capacity=capacity,min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    try:\n",
    "        for step in range(10):\n",
    "            if(coord.should_stop()):\n",
    "                break\n",
    "            print(sess.run([feature_batch,label_batch]))\n",
    "    except Exception as e:\n",
    "        coord.request_stop(e)\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reader - TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_tfrecord(data,label,shape,tfrecord_filename):\n",
    "    \"\"\"Write data as tfrecord, all input should be bytes\"\"\"\n",
    "    writer = tf.python_io.TFRecordWriter(tfrecord_filename)\n",
    "    feature = {\n",
    "        \"label\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[label])),\n",
    "        \"data\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[data])),\n",
    "        \"shape\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[shape]))\n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(3,2)\n",
    "label = np.random.randint(0,2,size=3)\n",
    "\n",
    "write_to_tfrecord(data.tobytes(),label.tobytes(),np.array(data.shape).tobytes(),\"./first_tfrecord.tfr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
